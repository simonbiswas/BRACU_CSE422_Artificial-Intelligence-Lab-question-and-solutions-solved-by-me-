# -*- coding: utf-8 -*-
"""Lab8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JznjgRlpt8ZQ2kaJ3wK9wOvgQFSnAhbA
"""

from google.colab import files
load_data = files.upload()

import sklearn
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.decomposition import PCA

#loading data
dataset = pd.read_csv('mushroom edibility classification dataset.csv')

# missing values
dataset.drop(dataset.columns[dataset.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)
dataset.isnull().sum()

dataset = dataset.dropna(axis = 0, subset = ['cap-shape', 'cap-color'])
print('unique values in class ' + str(dataset['class'].unique()))
print('unique values in bruises' + str(dataset['bruises'].unique()))

#encoding categorical features
enc = LabelEncoder()
dataset['class'] = enc.fit_transform(dataset['class'])
dataset['bruises'] = enc.fit_transform(dataset['bruises'])
dataset[['class', 'bruises']].head()

scaler = MinMaxScaler()
scaler.fit(dataset)
dataset_train_scaled = scaler.transform(dataset)
print('per-feature minimum before scaling:\n{}'.format(dataset.min(axis = 0)))
print('per-feature maximum before scaling:\n{}'.format(dataset.max(axis = 0)))
print('per-feature minimum after scaling:\n{}'.format(dataset_train_scaled.min(axis = 0)))
print('per-feature maximum after scaling:\n{}'.format(dataset_train_scaled.max(axis = 0)))

#splitting the dataset into features and labels
features = dataset[['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']]
label = dataset[['class']]
stratified = pd.DataFrame(label)
#8:2 train-test split
xTrain, xTest, yTrain, yTest = train_test_split(features, label, test_size = 0.20, stratify = stratified, random_state = 0)

#using the logistic regression 

perform_logisticRegression = LogisticRegression()
perform_logisticRegression.fit(xTrain, yTrain) 
predictions = perform_logisticRegression.predict(xTest)
accuracy_of_LogisticRegression = accuracy_score(yTest, predictions)
print(accuracy_of_LogisticRegression)

#using the decision tree

perform_decisionTree = DecisionTreeClassifier(criterion='entropy',random_state=1)
perform_decisionTree.fit(xTrain,yTrain)
yPred = perform_decisionTree.predict(xTest)
accuracy_of_DecisionTreeClassifier = accuracy_score(yPred, yTest)
print(accuracy_of_DecisionTreeClassifier)

#using Support Vector Machine

perform_supportVectorClassification = SVC(kernel="linear")
perform_supportVectorClassification.fit(xTrain, yTrain)
prediction_of_SupportVectorClassification = perform_supportVectorClassification.predict(xTest)
accuracy_of_SupportVectorMachine = accuracy_score(prediction_of_SupportVectorClassification, yTest)
print(accuracy_of_SupportVectorMachine)

#using Random Forest Classification

perform_randomForestClassifier = RandomForestClassifier(n_estimators = 50)
perform_randomForestClassifier.fit(xTrain, yTrain)
prediction_of_RandomForestClassifier = perform_randomForestClassifier.predict(xTest)
accuracy_of_RandomForestClassifier = accuracy_score(prediction_of_RandomForestClassifier, yTest)
print(accuracy_of_RandomForestClassifier)

#using Neural Network

perform_neuralNetwork = MLPClassifier(hidden_layer_sizes=(7), activation="relu", max_iter=1000)
perform_neuralNetwork.fit(xTrain, yTrain)
prediction_of_NeuralNetwork =perform_neuralNetwork.predict(xTest)
accuracy_of_NeuralNetwork = accuracy_score(prediction_of_NeuralNetwork, yTest)
print(accuracy_of_NeuralNetwork)

plt.bar(['Logistic\nRegression', 'Decision\nTree\nClassification', 'Support\nVector\nMachine', 'Random\nForest\nClassification', 'Neural\nNetwork'],[accuracy_of_LogisticRegression, accuracy_of_DecisionTreeClassifier, accuracy_of_SupportVectorMachine, accuracy_of_RandomForestClassifier, accuracy_of_NeuralNetwork])
plt.title('Accuracy Comparison among Algorithms ')
plt.show()

#using pca and reducing the number of feature vectors into half
columnCount = int(len(features.columns.values.tolist())/2) 
pca = PCA(n_components = columnCount)
principal_components = pca.fit_transform(features)
principalColummns = ["Principal Component" + str(i+1) for i in range(columnCount)]
principal_df = pd.DataFrame(data=principal_components, columns = principalColummns)
main_df=pd.concat([principal_df, dataset[["class"]]], axis=1)
main_df = main_df.dropna(how = 'any', axis = 0)

pcaFeature = main_df.drop('class', axis = 1)
pcaLabel = main_df['class']
pcaXTrain, pcaXTest, pcaYTrain, pcaYTest = train_test_split(pcaFeature , pcaLabel, test_size=0.2, stratify = pcaLabel, random_state=0)

pcaLabelName = ['class']
pcaFeatureName = principalColummns #list(features.columns.values.tolist())
scaler = MinMaxScaler()
pcaXTrain = pd.DataFrame(scaler.fit_transform(pcaXTrain), columns = pcaFeatureName)
pcaXTest = pd.DataFrame(scaler.fit_transform(pcaXTest), columns = pcaFeatureName)

#using Logistic Regression again

perform_logisitceRegressionModel = LogisticRegression()
perform_logisitceRegressionModel.fit(pcaXTrain, pcaYTrain)
prediction_of_LogisticRegressionModel = perform_logisitceRegressionModel.predict(pcaXTest)
pcaAccuracy_of_LogisticRegression = accuracy_score(pcaYTest, prediction_of_LogisticRegressionModel)
print(pcaAccuracy_of_LogisticRegression)

#using Decision Tree again

perform_decisionTreeClassification = DecisionTreeClassifier(criterion='entropy',random_state=1)
perform_decisionTreeClassification.fit(pcaXTrain,pcaYTrain)
prediction_of_DecisionTreeClassification = perform_decisionTreeClassification.predict(pcaXTest)
pcaAccuracy_of_DecisionTreeClassifier = accuracy_score(prediction_of_DecisionTreeClassification, pcaYTest)
print(pcaAccuracy_of_DecisionTreeClassifier)

#using Support Vector Machine again

perform_supportVectorClassification = SVC(kernel="linear")
perform_supportVectorClassification.fit(pcaXTrain, pcaYTrain)
prediction_of_SupportVectorClassification = perform_supportVectorClassification.predict(pcaXTest)
pcaAccuracy_of_SupportVectorMachine = accuracy_score(prediction_of_SupportVectorClassification, pcaYTest)
print(pcaAccuracy_of_SupportVectorMachine)

#using Random Forest Classification again

perform_randomForestClassifier = RandomForestClassifier(n_estimators = 50)
perform_randomForestClassifier.fit(pcaXTrain, pcaYTrain)
prediction_of_RandomForestClassifier = perform_randomForestClassifier.predict(pcaXTest)
pcaAccuracy_of_RandomForestClassifier = accuracy_score(prediction_of_RandomForestClassifier, pcaYTest)
print(pcaAccuracy_of_RandomForestClassifier)

#using Neural Network again

perform_neuralNetwork = MLPClassifier(hidden_layer_sizes=(7), activation="relu", max_iter=100000)
perform_neuralNetwork.fit(pcaXTrain, pcaYTrain)
prediction_of_NeuralNetwork = perform_neuralNetwork.predict(pcaXTest)
pcaAccuracy_of_NeuralNetwork = accuracy_score(prediction_of_NeuralNetwork, pcaYTest)
print(pcaAccuracy_of_NeuralNetwork)

plt.bar(['Logistic\nRegression', 'Decision\nTree\nClassification', 'Support\nVector\nMachine', 'Random\nForest\nClassification', 'Neural\nNetwork'],[pcaAccuracy_of_LogisticRegression, pcaAccuracy_of_DecisionTreeClassifier, pcaAccuracy_of_SupportVectorMachine, pcaAccuracy_of_RandomForestClassifier, pcaAccuracy_of_NeuralNetwork])
plt.title('Accuracy Comparison among Algorithms ')
plt.show()

plt.bar(['Before PCA', 'After PCA'],[accuracy_of_LogisticRegression, pcaAccuracy_of_LogisticRegression])
plt.title('Accuracy Comparison of Logistic Regression ')
plt.show()

plt.bar(['Before PCA', 'After PCA'],[accuracy_of_SupportVectorMachine, pcaAccuracy_of_SupportVectorMachine])
plt.title('Accuracy Comparison of Support Vector Machine')
plt.show()

plt.bar(['Before PCA', 'After PCA'],[accuracy_of_RandomForestClassifier, pcaAccuracy_of_RandomForestClassifier])
plt.title('Accuracy Comparison of Random Forest Classifier ')
plt.show()

plt.bar(['Before PCA', 'After PCA'],[accuracy_of_NeuralNetwork, pcaAccuracy_of_NeuralNetwork])
plt.title('Accuracy Comparison of Neural Network ')
plt.show()